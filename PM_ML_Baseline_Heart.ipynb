{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadAsad0/Medical-Diagnosis-Risk-Scoring-using-Bayesian-Networks/blob/main/PM_ML_Baseline_Heart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTOK7hjPi7Wm",
        "outputId": "6831f8e8-de33-4846-b4f2-e5af8b8fcc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import for dataset\n",
        "from ucimlrepo import fetch_ucirepo"
      ],
      "metadata": {
        "id": "-o1QFQ7T7aJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "X = heart_disease.data.features\n",
        "y = heart_disease.data.targets\n",
        "\n",
        "print(\"X shape: \", X.shape)\n",
        "print(\"y shape: \", y.shape)\n",
        "\n",
        "print(X.describe())\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "N4Uvn78y7lqM",
        "outputId": "51eca6a6-7da3-4f23-9eb5-124298d46907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape:  (303, 13)\n",
            "y shape:  (303, 1)\n",
            "              age         sex          cp    trestbps        chol         fbs  \\\n",
            "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
            "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
            "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
            "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
            "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
            "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
            "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
            "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
            "\n",
            "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
            "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000   \n",
            "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.672241   \n",
            "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.937438   \n",
            "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
            "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
            "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
            "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
            "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
            "\n",
            "             thal  \n",
            "count  301.000000  \n",
            "mean     4.734219  \n",
            "std      1.939706  \n",
            "min      3.000000  \n",
            "25%      3.000000  \n",
            "50%      3.000000  \n",
            "75%      7.000000  \n",
            "max      7.000000  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "num\n",
              "0      164\n",
              "1       55\n",
              "2       36\n",
              "3       35\n",
              "4       13\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "J48UBWmhbCCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate X and y\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Drop samples with null values\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "df['num'] = (df['num'] > 0).astype(int)\n",
        "\n",
        "# Features & Split\n",
        "X = df.drop('num', axis=1)\n",
        "y = df['num']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale Features (for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "c8QrTwFWa-Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Class"
      ],
      "metadata": {
        "id": "rfiSxIRf7ZCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "kWHOrfwg7cPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "lr_auc = roc_auc_score(y_test, y_pred_proba_lr)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {lr_accuracy:.4f}\")\n",
        "print(f\"AUC-ROC Score: {lr_auc:.4f}\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores_lr = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"\\n5-Fold CV Accuracy: {cv_scores_lr.mean():.4f} (+/- {cv_scores_lr.std():.4f})\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=['No Disease', 'Disease']))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "\n",
        "# Feature importance for Logistic Regression\n",
        "feature_importance_lr = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': np.abs(lr_model.coef_[0])\n",
        "}).sort_values('Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Important Features (Logistic Regression):\")\n",
        "print(feature_importance_lr.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSCWT89z7jeX",
        "outputId": "ad292f9e-d814-4b11-ef9d-d6245ff7a7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.8333\n",
            "AUC-ROC Score: 0.9498\n",
            "\n",
            "5-Fold CV Accuracy: 0.8221 (+/- 0.0764)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  No Disease       0.82      0.88      0.85        32\n",
            "     Disease       0.85      0.79      0.81        28\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.83      0.83      0.83        60\n",
            "weighted avg       0.83      0.83      0.83        60\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[28  4]\n",
            " [ 6 22]]\n",
            "\n",
            "Top 5 Important Features (Logistic Regression):\n",
            "    Feature  Coefficient\n",
            "11       ca     0.958461\n",
            "12     thal     0.738613\n",
            "2        cp     0.507960\n",
            "1       sex     0.484582\n",
            "9   oldpeak     0.444296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "n_ei7XAR7la4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBoost\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "xgb_auc = roc_auc_score(y_test, y_pred_proba_xgb)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"AUC-ROC Score: {xgb_auc:.4f}\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"\\n5-Fold CV Accuracy: {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std():.4f})\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=['No Disease', 'Disease']))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "\n",
        "# Feature importance for XGBoost\n",
        "feature_importance_xgb = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': xgb_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Important Features (XGBoost):\")\n",
        "print(feature_importance_xgb.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XMCMjy_7o_L",
        "outputId": "1f229af0-2fb6-4329-e94c-dbf7b392d86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.8333\n",
            "AUC-ROC Score: 0.9141\n",
            "\n",
            "5-Fold CV Accuracy: 0.8010 (+/- 0.0843)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  No Disease       0.82      0.88      0.85        32\n",
            "     Disease       0.85      0.79      0.81        28\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.83      0.83      0.83        60\n",
            "weighted avg       0.83      0.83      0.83        60\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[28  4]\n",
            " [ 6 22]]\n",
            "\n",
            "Top 5 Important Features (XGBoost):\n",
            "   Feature  Importance\n",
            "12    thal    0.268721\n",
            "2       cp    0.189275\n",
            "11      ca    0.098394\n",
            "10   slope    0.083740\n",
            "8    exang    0.063999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison"
      ],
      "metadata": {
        "id": "V4KVfDlD_Mff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'XGBoost'],\n",
        "    'Test Accuracy': [lr_accuracy, xgb_accuracy],\n",
        "    'AUC-ROC': [lr_auc, xgb_auc],\n",
        "    'CV Accuracy': [cv_scores_lr.mean(), cv_scores_xgb.mean()]\n",
        "})\n",
        "\n",
        "print(\"\\n\", comparison.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7v9JkzI_Ll_",
        "outputId": "473e26a3-8200-43eb-d895-d2786fc9c9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               Model  Test Accuracy  AUC-ROC  CV Accuracy\n",
            "Logistic Regression       0.833333 0.949777     0.822074\n",
            "            XGBoost       0.833333 0.914062     0.800975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Class"
      ],
      "metadata": {
        "id": "FZtexZt27pl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "C3NoD8qPuVoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = heart_disease.data.features\n",
        "y = heart_disease.data.targets\n",
        "\n",
        "# Concatenate X and y\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Drop samples with null values\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Features & Split\n",
        "X = df.drop('num', axis=1)\n",
        "y = df['num']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale Features (for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "hAK6gBtiuVoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "qWFlRnkWbZGt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdxctUetMRms",
        "outputId": "5d6613be-73c6-454a-f701-7fe96d423c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.6000\n",
            "Weighted AUC-ROC Score (OvR): 0.8632\n",
            "\n",
            "5-Fold CV Accuracy: 0.5908 (+/- 0.0357)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.79      0.94      0.86        32\n",
            "     Class 1       0.50      0.27      0.35        11\n",
            "     Class 2       0.00      0.00      0.00         7\n",
            "     Class 3       0.33      0.43      0.38         7\n",
            "     Class 4       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.60        60\n",
            "   macro avg       0.32      0.33      0.32        60\n",
            "weighted avg       0.55      0.60      0.57        60\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[30  1  0  0  1]\n",
            " [ 6  3  2  0  0]\n",
            " [ 2  1  0  4  0]\n",
            " [ 0  0  3  3  1]\n",
            " [ 0  1  0  2  0]]\n",
            "\n",
            "Confusion Matrix (rows=actual, columns=predicted)\n",
            "        Pred 0  Pred 1  Pred 2  Pred 3  Pred 4\n",
            "True 0      30       1       0       0       1\n",
            "True 1       6       3       2       0       0\n",
            "True 2       2       1       0       4       0\n",
            "True 3       0       0       3       3       1\n",
            "True 4       0       1       0       2       0\n",
            "\n",
            "Top 5 Important Features (Logistic Regression):\n",
            "    Feature  Avg_Abs_Coefficient\n",
            "11       ca             0.498688\n",
            "9   oldpeak             0.311933\n",
            "7   thalach             0.261496\n",
            "10    slope             0.245286\n",
            "12     thal             0.235875\n"
          ]
        }
      ],
      "source": [
        "# Train Logistic Regression with multiclass support\n",
        "lr_model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    solver='lbfgs'\n",
        ")\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {lr_accuracy:.4f}\")\n",
        "\n",
        "# For multiclass, calculate AUC using ovr (one-vs-rest)\n",
        "try:\n",
        "    lr_auc = roc_auc_score(y_test, y_pred_proba_lr, multi_class='ovr', average='weighted')\n",
        "    print(f\"Weighted AUC-ROC Score (OvR): {lr_auc:.4f}\")\n",
        "except:\n",
        "    print(\"AUC-ROC: Not calculated (some classes may not be present in test set)\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores_lr = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"\\n5-Fold CV Accuracy: {cv_scores_lr.mean():.4f} (+/- {cv_scores_lr.std():.4f})\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "class_names = [f'Class {i}' for i in sorted(y.unique())]\n",
        "print(classification_report(y_test, y_pred_lr, target_names=class_names, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "print(cm_lr)\n",
        "print(\"\\nConfusion Matrix (rows=actual, columns=predicted)\")\n",
        "cm_df_lr = pd.DataFrame(cm_lr,\n",
        "                         index=[f'True {i}' for i in sorted(y.unique())],\n",
        "                         columns=[f'Pred {i}' for i in sorted(y.unique())])\n",
        "print(cm_df_lr)\n",
        "\n",
        "# Feature importance for Logistic Regression (average across classes)\n",
        "feature_importance_lr = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Avg_Abs_Coefficient': np.abs(lr_model.coef_).mean(axis=0)\n",
        "}).sort_values('Avg_Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Important Features (Logistic Regression):\")\n",
        "print(feature_importance_lr.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Classifier"
      ],
      "metadata": {
        "id": "7r16TQqjbi17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train XGBoost with multiclass\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    objective='multi:softprob',  # Multiclass classification\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_proba_xgb = xgb_model.predict_proba(X_test)\n",
        "\n",
        "# Evaluation\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "# For multiclass, calculate AUC using ovr (one-vs-rest)\n",
        "try:\n",
        "    xgb_auc = roc_auc_score(y_test, y_pred_proba_xgb, multi_class='ovr', average='weighted')\n",
        "    print(f\"Weighted AUC-ROC Score (OvR): {xgb_auc:.4f}\")\n",
        "except:\n",
        "    print(\"AUC-ROC: Not calculated (some classes may not be present in test set)\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"\\n5-Fold CV Accuracy: {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std():.4f})\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=class_names, zero_division=0))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(cm_xgb)\n",
        "print(\"\\nConfusion Matrix (rows=actual, columns=predicted)\")\n",
        "cm_df_xgb = pd.DataFrame(cm_xgb,\n",
        "                          index=[f'True {i}' for i in sorted(y.unique())],\n",
        "                          columns=[f'Pred {i}' for i in sorted(y.unique())])\n",
        "print(cm_df_xgb)\n",
        "\n",
        "# Feature importance for XGBoost\n",
        "feature_importance_xgb = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': xgb_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Important Features (XGBoost):\")\n",
        "print(feature_importance_xgb.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epVRpGsEaiI2",
        "outputId": "19aff457-6700-4ee5-8b07-e811181ba3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.5667\n",
            "Weighted AUC-ROC Score (OvR): 0.8303\n",
            "\n",
            "5-Fold CV Accuracy: 0.5652 (+/- 0.0430)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.85      0.91      0.88        32\n",
            "     Class 1       0.31      0.36      0.33        11\n",
            "     Class 2       0.17      0.14      0.15         7\n",
            "     Class 3       0.00      0.00      0.00         7\n",
            "     Class 4       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.57        60\n",
            "   macro avg       0.27      0.28      0.27        60\n",
            "weighted avg       0.53      0.57      0.55        60\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[29  1  2  0  0]\n",
            " [ 4  4  1  2  0]\n",
            " [ 1  3  1  1  1]\n",
            " [ 0  4  2  0  1]\n",
            " [ 0  1  0  2  0]]\n",
            "\n",
            "Confusion Matrix (rows=actual, columns=predicted)\n",
            "        Pred 0  Pred 1  Pred 2  Pred 3  Pred 4\n",
            "True 0      29       1       2       0       0\n",
            "True 1       4       4       1       2       0\n",
            "True 2       1       3       1       1       1\n",
            "True 3       0       4       2       0       1\n",
            "True 4       0       1       0       2       0\n",
            "\n",
            "Top 5 Important Features (XGBoost):\n",
            "    Feature  Importance\n",
            "2        cp    0.183562\n",
            "12     thal    0.123500\n",
            "11       ca    0.106137\n",
            "9   oldpeak    0.077948\n",
            "10    slope    0.074122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison"
      ],
      "metadata": {
        "id": "1wuoovLAHM67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'XGBoost'],\n",
        "    'Test Accuracy': [lr_accuracy, xgb_accuracy],\n",
        "    'CV Accuracy': [cv_scores_lr.mean(), cv_scores_xgb.mean()],\n",
        "    'CV Std Dev': [cv_scores_lr.std(), cv_scores_xgb.std()]\n",
        "})\n",
        "\n",
        "print(\"\\n\", comparison.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ADDITIONAL INSIGHTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nClass distribution in predictions:\")\n",
        "print(\"\\nLogistic Regression predictions:\")\n",
        "print(pd.Series(y_pred_lr).value_counts().sort_index())\n",
        "print(\"\\nXGBoost predictions:\")\n",
        "print(pd.Series(y_pred_xgb).value_counts().sort_index())\n",
        "print(\"\\nActual test set distribution:\")\n",
        "print(y_test.value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1NWxYza8KgP",
        "outputId": "66ac59bf-79dc-4385-d350-008de685c671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               Model  Test Accuracy  CV Accuracy  CV Std Dev\n",
            "Logistic Regression       0.600000     0.590780    0.035702\n",
            "            XGBoost       0.566667     0.565248    0.042985\n",
            "\n",
            "============================================================\n",
            "ADDITIONAL INSIGHTS\n",
            "============================================================\n",
            "\n",
            "Class distribution in predictions:\n",
            "\n",
            "Logistic Regression predictions:\n",
            "0    38\n",
            "1     6\n",
            "2     5\n",
            "3     9\n",
            "4     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "XGBoost predictions:\n",
            "0    34\n",
            "1    13\n",
            "2     6\n",
            "3     5\n",
            "4     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Actual test set distribution:\n",
            "num\n",
            "0    32\n",
            "1    11\n",
            "2     7\n",
            "3     7\n",
            "4     3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gOmZxP2_JrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}